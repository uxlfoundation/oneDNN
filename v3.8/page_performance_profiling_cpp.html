

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Performance Profiling Example &#8212; oneDNN v3.8.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-pygments.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script src="_static/target-highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'page_performance_profiling_cpp';</script>
    <link rel="icon" href="_static/favicons.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CPU Dispatcher Control" href="dev_guide_cpu_dispatcher_control.html" />
    <link rel="prev" title="Inspecting JIT Code" href="dev_guide_inspecting_jit.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/oneAPI-rgb-rev-100.png" class="logo__image only-light" alt=""/>
    <script>document.write(`<img src="_static/oneAPI-rgb-rev-100.png" class="logo__image only-dark" alt=""/>`);</script>
  
  
    <p class="title logo__title">oneDNN v3.8 Documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="build_and_link.html">Building and Linking</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_build.html">Build from Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_build_options.html">Build Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_link.html">Linking to the Library</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="programming_model.html">Programming Model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_basic_concepts.html">Basic Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_getting_started_cpp.html">Getting started</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_memory_format_propagation_cpp.html">Memory Format Propagation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="dev_guide_inference_and_training_aspects.html">Inference and Training Aspects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_inference.html">Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_inference_int8.html">Int8 Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_training_bf16.html">Bfloat16 Training</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="dev_guide_attributes.html">Primitive Attributes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_fpmath_mode.html">Primitive Attributes: floating-point math mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_accumulation_mode.html">Primitive Attributes: accumulation mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_rounding_mode.html">Primitive Attributes: rounding mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_deterministic.html">Primitive Attributes: deterministic</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_quantization.html">Primitive Attributes: Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_post_ops.html">Primitive Attributes: Post-ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_attributes_scratchpad.html">Primitive Attributes: Scratchpad</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_data_types.html">Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_cross_engine_reorder_cpp.html">Reorder between CPU and GPU engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_c_and_cpp_apis.html">API</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="interop_with_dpcpp_and_opencl.html">Interoperability with DPC++ and OpenCL</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_opencl_interoperability.html">OpenCL Interoperability</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_dpcpp_interoperability.html">DPC++ Interoperability</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="supported_primitives.html">Supported Primitives</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_convolution.html">Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_inner_product.html">Inner Product</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_matmul.html">Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_rnn.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_batch_normalization.html">Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_binary.html">Binary</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_concat.html">Concat</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_eltwise.html">Eltwise</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_group_normalization.html">Group Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_layer_normalization.html">Layer Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_lrn.html">Local Response Normalization (LRN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_pooling.html">Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_prelu.html">PReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_resampling.html">Resampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_shuffle.html">Shuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_softmax.html">Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_sum.html">Sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_reorder.html">Reorder</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_reduction.html">Reduction</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="graph_extension.html">Graph Extension</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="graph_programming_model.html">Programming Model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_basic_concepts.html">Basic Concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_low_precision.html">Low Precision</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="graph_supported_operations.html">Supported Operations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_abs.html">Abs</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_absbackward.html">AbsBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_add.html">Add</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_avgpool.html">AvgPool</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_avgpoolbackward.html">AvgPoolBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_batchnormforwardtraining.html">BatchNormForwardTraining</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_batchnorminference.html">BatchNormInference</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_batchnormtrainingbackward.html">BatchNormTrainingBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_biasadd.html">BiasAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_biasaddbackward.html">BiasAddBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_clamp.html">Clamp</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_clampbackward.html">ClampBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_concat.html">Concat</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convolution.html">Convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convolutionbackwarddata.html">ConvolutionBackwardData</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convolutionbackwardweights.html">ConvolutionBackwardWeights</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convtranspose.html">ConvTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convtransposebackwarddata.html">ConvTransposeBackwardData</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_convtransposebackwardweights.html">ConvTransposeBackwardWeights</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_dequantize.html">Dequantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_divide.html">Divide</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_dynamicdequantize.html">DynamicDequantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_dynamicquantize.html">DynamicQuantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_elu.html">Elu</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_elubackward.html">EluBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_end.html">End</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_exp.html">Exp</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_groupnorm.html">GroupNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_gelu.html">GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_gelubackward.html">GELUBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_hardsigmoid.html">HardSigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_hardsigmoidbackward.html">HardSigmoidBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_hardswish.html">HardSwish</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_hardswishbackward.html">HardSwishBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_interpolate.html">Interpolate</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_interpolatebackward.html">InterpolateBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_layernorm.html">LayerNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_layernormbackward.html">LayerNormBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_leakyrelu.html">LeakyReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_log.html">Log</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_logsoftmax.html">LogSoftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_logsoftmaxbackward.html">LogSoftmaxBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_matmul.html">MatMul</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_maximum.html">Maximum</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_maxpool.html">MaxPool</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_maxpoolbackward.html">MaxPoolBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_minimum.html">Minimum</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_mish.html">Mish</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_mishbackward.html">MishBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_multiply.html">Multiply</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_pow.html">Pow</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_prelu.html">PReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_prelubackward.html">PReLUBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_quantize.html">Quantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reciprocal.html">Reciprocal</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducel1.html">ReduceL1</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducel2.html">ReduceL2</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducemax.html">ReduceMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducemean.html">ReduceMean</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducemin.html">ReduceMin</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reduceprod.html">ReduceProd</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reducesum.html">ReduceSum</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_relu.html">ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_relubackward.html">ReLUBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_reorder.html">Reorder</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_round.html">Round</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_select.html">Select</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_sigmoid.html">Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_sigmoidbackward.html">SigmoidBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_softmax.html">SoftMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_softmaxbackward.html">SoftMaxBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_softplus.html">SoftPlus</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_softplusbackward.html">SoftPlusBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_sqrt.html">Sqrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_sqrtbackward.html">SqrtBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_square.html">Square</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_squareddifference.html">SquaredDifference</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_staticreshape.html">StaticReshape</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_statictranspose.html">StaticTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_subtract.html">Subtract</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_tanh.html">Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_tanhbackward.html">TanhBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_typecast.html">TypeCast</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_op_wildcard.html">Wildcard</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="graph_fusion_patterns.html">Fusion Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_gated_mlp.html">Gated Multi-Layer Perceptron (Gated-MLP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_gqa.html">Grouped Query Attention (GQA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_sdpa_compressed_kv.html">SDPA with Compressed Key and Value</a></li>
<li class="toctree-l3"><a class="reference internal" href="dev_guide_graph_sdpa.html">Scaled Dot-Product Attention (SDPA)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_graph_dump.html">Graph Dump</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_constant_tensor_cache.html">Constant Tensor Cache</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="dev_guide_examples.html">Examples</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="performance_profiling_and_inspection.html">Performance Profiling and Inspection</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dev_guide_verbose.html">Verbose Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_performance_settings.html">Configuring oneDNN for Benchmarking</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_benchdnn.html">Benchmarking Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_profilers.html">Profiling oneDNN Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_inspecting_jit.html">Inspecting JIT Code</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Performance Profiling Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_cpu_dispatcher_control.html">CPU Dispatcher Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_cpu_isa_hints.html">CPU ISA Hints</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_verbose_table.html">Verbose Message Catalogue</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="advanced_topics.html">Advanced Topics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_transition_to_dnnl.html">Transitioning from Intel MKL-DNN to oneDNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_understanding_memory_formats.html">Understanding Memory Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_int8_computations.html">Nuances of int8 Computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_primitive_cache.html">Primitive Cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_persistent_cache.html">Persistent Cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_threadpool.html">Using oneDNN with Threadpool-Based Threading</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_experimental.html">Experimental features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ukernels.html">Ukernels</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_ukernel_basic_concepts.html">Basic Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_ukernel_brgemm.html">Batch-Reduce General Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="dev_guide_ukernel_transform.html">Data transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_cpu_brgemm_example_cpp.html">BRGeMM ukernel example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="group_dnnl_api.html">oneDNN API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_primitives.html">Primitives</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_primitives_common.html">Common</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_alg_kind_t.html">enum dnnl_alg_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_normalization_flags_t.html">enum dnnl_normalization_flags_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_primitive_kind_t.html">enum dnnl_primitive_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_prop_kind_t.html">enum dnnl_prop_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_query_t.html">enum dnnl_query_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_normalization_flags.html">enum dnnl::normalization_flags</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_query.html">enum dnnl::query</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_exec_arg_t.html">struct dnnl_exec_arg_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive.html">struct dnnl_primitive</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive_desc.html">struct dnnl_primitive_desc</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive-2.html">struct dnnl::primitive</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive_desc-2.html">struct dnnl::primitive_desc</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive_desc_base.html">struct dnnl::primitive_desc_base</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_attributes.html">Attributes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_algorithm.html">enum dnnl::algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rounding_mode_t.html">enum dnnl_rounding_mode_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_scratchpad_mode_t.html">enum dnnl_scratchpad_mode_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_prop_kind.html">enum dnnl::prop_kind</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rounding_mode.html">enum dnnl::rounding_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_scratchpad_mode.html">enum dnnl::scratchpad_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_post_ops.html">struct dnnl_post_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive_attr.html">struct dnnl_primitive_attr</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_post_ops-2.html">struct dnnl::post_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_primitive_attr-2.html">struct dnnl::primitive_attr</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_reorder.html">Reorder</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_reorder.html">struct dnnl::reorder</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_concat.html">Concat</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_concat.html">struct dnnl::concat</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_sum.html">Sum</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_sum.html">struct dnnl::sum</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_binary.html">Binary</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_binary.html">struct dnnl::binary</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_convolution.html">Convolution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_convolution_backward_data.html">struct dnnl::convolution_backward_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_convolution_backward_weights.html">struct dnnl::convolution_backward_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_convolution_forward.html">struct dnnl::convolution_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_deconvolution.html">Deconvolution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_deconvolution_backward_data.html">struct dnnl::deconvolution_backward_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_deconvolution_backward_weights.html">struct dnnl::deconvolution_backward_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_deconvolution_forward.html">struct dnnl::deconvolution_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_shuffle.html">Shuffle</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_shuffle_backward.html">struct dnnl::shuffle_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_shuffle_forward.html">struct dnnl::shuffle_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_eltwise.html">Eltwise</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_eltwise_backward.html">struct dnnl::eltwise_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_eltwise_forward.html">struct dnnl::eltwise_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_softmax.html">Softmax</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_softmax_backward.html">struct dnnl::softmax_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_softmax_forward.html">struct dnnl::softmax_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_pooling.html">Pooling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_pooling_backward.html">struct dnnl::pooling_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_pooling_forward.html">struct dnnl::pooling_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_prelu.html">PReLU</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_prelu_backward.html">struct dnnl::prelu_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_prelu_forward.html">struct dnnl::prelu_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_lrn.html">LRN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lrn_backward.html">struct dnnl::lrn_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lrn_forward.html">struct dnnl::lrn_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_batch_normalization.html">Batch Normalization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_batch_normalization_backward.html">struct dnnl::batch_normalization_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_batch_normalization_forward.html">struct dnnl::batch_normalization_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_group_normalization.html">Group Normalization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_group_normalization_backward.html">struct dnnl::group_normalization_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_group_normalization_forward.html">struct dnnl::group_normalization_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_layer_normalization.html">Layer Normalization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_layer_normalization_backward.html">struct dnnl::layer_normalization_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_layer_normalization_forward.html">struct dnnl::layer_normalization_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_inner_product.html">Inner Product</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_inner_product_backward_data.html">struct dnnl::inner_product_backward_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_inner_product_backward_weights.html">struct dnnl::inner_product_backward_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_inner_product_forward.html">struct dnnl::inner_product_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_rnn.html">RNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rnn_direction_t.html">enum dnnl_rnn_direction_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rnn_flags_t.html">enum dnnl_rnn_flags_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rnn_direction.html">enum dnnl::rnn_direction</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_rnn_flags.html">enum dnnl::rnn_flags</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_augru_backward.html">struct dnnl::augru_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_augru_forward.html">struct dnnl::augru_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_gru_backward.html">struct dnnl::gru_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_gru_forward.html">struct dnnl::gru_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lbr_augru_backward.html">struct dnnl::lbr_augru_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lbr_augru_forward.html">struct dnnl::lbr_augru_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lbr_gru_backward.html">struct dnnl::lbr_gru_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lbr_gru_forward.html">struct dnnl::lbr_gru_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lstm_backward.html">struct dnnl::lstm_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_lstm_forward.html">struct dnnl::lstm_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_rnn_primitive_desc_base.html">struct dnnl::rnn_primitive_desc_base</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_vanilla_rnn_backward.html">struct dnnl::vanilla_rnn_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_vanilla_rnn_forward.html">struct dnnl::vanilla_rnn_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_matmul.html">Matrix Multiplication</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_matmul.html">struct dnnl::matmul</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_resampling.html">Resampling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_resampling_backward.html">struct dnnl::resampling_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_resampling_forward.html">struct dnnl::resampling_forward</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_reduction.html">Reduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_reduction.html">struct dnnl::reduction</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_primitive_cache.html">Primitive Cache</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_profiling.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="enum_dnnl_profiling_data_kind.html">enum dnnl::profiling_data_kind</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_blas.html">BLAS functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_common.html">Common API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_engine.html">Engine</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_engine_kind_t.html">enum dnnl_engine_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_engine.html">struct dnnl_engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_engine-2.html">struct dnnl::engine</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_stream.html">Stream</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_stream_flags_t.html">enum dnnl_stream_flags_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_stream.html">struct dnnl_stream</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_stream-2.html">struct dnnl::stream</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_fpmath_mode.html">Floating-point Math Mode</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_fpmath_mode_t.html">enum dnnl_fpmath_mode_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_fpmath_mode.html">enum dnnl::fpmath_mode</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_service.html">Service</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_cpu_isa.html">enum dnnl::cpu_isa</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_cpu_isa_hints.html">enum dnnl::cpu_isa_hints</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_cpu_isa_hints_t.html">enum dnnl_cpu_isa_hints_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_cpu_isa_t.html">enum dnnl_cpu_isa_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_status.html">enum dnnl::status</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_version_t.html">struct dnnl_version_t</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_utils.html">Utilities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_status_t.html">enum dnnl_status_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_error.html">struct dnnl::error</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_handle.html">template struct dnnl::handle</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_handle_traits.html">template struct dnnl::handle_traits</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_accumulation_mode.html">Accumulation Mode</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_accumulation_mode.html">enum dnnl::accumulation_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_accumulation_mode_t.html">enum dnnl_accumulation_mode_t</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_data_types.html">Data types</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_data_type_t.html">enum dnnl_data_type_t</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_memory.html">Memory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_format_kind_t.html">enum dnnl_format_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_format_tag_t.html">enum dnnl_format_tag_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_profiling_data_kind_t.html">enum dnnl_profiling_data_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_sparse_encoding_t.html">enum dnnl_sparse_encoding_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_memory.html">struct dnnl_memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_memory_desc.html">struct dnnl_memory_desc</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_memory-2.html">struct dnnl::memory</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_graph_api.html">Graph API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_allocator.html">Allocator</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_allocator.html">class dnnl::graph::allocator</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_engine.html">Engine</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_logical_tensor.html">Logical Tensor</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_graph_layout_type_t.html">enum dnnl_graph_layout_type_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_graph_tensor_property_t.html">enum dnnl_graph_tensor_property_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_graph_logical_tensor_t.html">struct dnnl_graph_logical_tensor_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_logical_tensor.html">class dnnl::graph::logical_tensor</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_tensor.html">Tensor</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_tensor.html">class dnnl::graph::tensor</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_op.html">Op</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_graph_op_attr_t.html">enum dnnl_graph_op_attr_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_graph_op_kind_t.html">enum dnnl_graph_op_kind_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_op.html">class dnnl::graph::op</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_partition.html">Partition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_graph_partition_policy_t.html">enum dnnl_graph_partition_policy_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_partition.html">class dnnl::graph::partition</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_compiled_partition.html">Compiled Partition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_graph_inplace_pair_t.html">struct dnnl_graph_inplace_pair_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_compiled_partition.html">class dnnl::graph::compiled_partition</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_graph.html">Graph</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="class_dnnl_graph_graph.html">class dnnl::graph::graph</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_compiled_partition_cache.html">Compiled Partition Cache</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_constant_tensor_cache.html">Constant Tensor Cache</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_graph_api_interop.html">Runtime interoperability API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="group_dnnl_graph_api_ocl_interop.html">OpenCL interoperability API</a></li>
<li class="toctree-l4"><a class="reference internal" href="group_dnnl_graph_api_sycl_interop.html">SYCL interoperability API</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="namespace_dnnl_graph.html">namespace dnnl::graph</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_interop.html">Runtime interoperability API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_ocl_interop.html">OpenCL interoperability API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="namespace_dnnl_ocl_interop.html">namespace dnnl::ocl_interop</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_ocl_interop_memory_kind_t.html">enum dnnl_ocl_interop_memory_kind_t</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_sycl_interop.html">SYCL interoperability API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="namespace_dnnl_sycl_interop.html">namespace dnnl::sycl_interop</a></li>
<li class="toctree-l4"><a class="reference internal" href="enum_dnnl_sycl_interop_memory_kind_t.html">enum dnnl_sycl_interop_memory_kind_t</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_threadpool_interop.html">Threadpool interoperability API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="namespace_dnnl_threadpool_interop.html">namespace dnnl::threadpool_interop</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="group_dnnl_api_ukernel.html">Ukernels</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="group_dnnl_api_ukernel_brgemm.html">BRGeMM ukernel</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_ukernel_brgemm.html">struct dnnl::ukernel::brgemm</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_brgemm.html">struct dnnl_brgemm</a></li>
<li class="toctree-l4"><a class="reference internal" href="struct_dnnl_transform.html">struct dnnl_transform</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="namespace_dnnl_ukernel.html">namespace dnnl::ukernel</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="enum_dnnl_pack_type_t.html">enum dnnl_pack_type_t</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="struct_dnnl_ukernel_attr_params.html">struct dnnl_ukernel_attr_params</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="namespace_dnnl.html">namespace dnnl</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="namespace_oneapi.html">namespace oneapi</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/uxlfoundation/oneDNN" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/uxlfoundation/oneDNN/issues/new?title=Issue%20on%20page%20%2Fpage_performance_profiling_cpp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/page_performance_profiling_cpp.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Performance Profiling Example</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#walkthrough">Walkthrough</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-implementation">Naive Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#blocked-format-implementation">Blocked format implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fused-implementation">Fused Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-summary">Performance summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-notice">Configuration Notice</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="performance-profiling-example">
<span id="doxid-performance-profiling-cpp"></span><span id="index-0"></span><h1>Performance Profiling Example<a class="headerlink" href="#performance-profiling-example" title="Permalink to this heading">#</a></h1>
<p>This example demonstrates the best practices for application performance optimizations with oneDNN.</p>
<p>This example demonstrates the best practices for application performance optimizations with oneDNN.</p>
<p>Example code: <a class="reference internal" href="example_performance_profiling.cpp.html#doxid-performance-profiling-8cpp-example"><span class="std std-ref">performance_profiling.cpp</span></a></p>
<p>This example uses <a class="reference internal" href="dev_guide_verbose.html#doxid-dev-guide-verbose"><span class="std std-ref">ONEDNN_VERBOSE</span></a> trace output to tune oneDNN code to align with the <a class="reference internal" href="dev_guide_inference.html#doxid-dev-guide-inference"><span class="std std-ref">best practices</span></a>.</p>
<p>It assumes knowledge of memory formats and their usage in oneDNN. You can read more about this topic <a class="reference internal" href="page_memory_format_propagation_cpp.html#doxid-memory-format-propagation-cpp"><span class="std std-ref">here</span></a>.</p>
<p>Additionally, see the <a class="reference internal" href="dev_guide_performance_settings.html#doxid-dev-guide-performance-settings"><span class="std std-ref">article for recommended environment for</span></a> running benchmarks”.</p>
<p>The example has three different implementations of the mathematical operation:</p>
<ol class="arabic simple">
<li><p>Naive implementation executes 2D convolution followed by ReLU on the data in NCHW format. This implementation does not align with oneDNN best practices and results in suboptimal performance.</p></li>
<li><p>Blocked format implementation executes the same operations sequence on the blocked format optimized for convolution performance. This implementation uses <code class="docutils literal notranslate"><span class="pre">format_tag=ANY</span></code> to create a convolution memory descriptor to determine the data format optimal for the convolution implementation. It then propagates the blocked format to the non-intensive ReLU. This implementation results in better overall performance than the naive implementation.</p></li>
<li><p>Fused implementation executes convolution fused with ReLU on blocked data format. This implementation uses <code class="docutils literal notranslate"><span class="pre">format_tag=ANY</span></code> to create a convolution memory descriptor, and then adds ReLU as a post-op to the convolution primitive. This version implements all of the best practices for inference resulting in the best overall performance.</p></li>
</ol>
<section id="walkthrough">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-walkthrough"></span><h2>Walkthrough<a class="headerlink" href="#walkthrough" title="Permalink to this heading">#</a></h2>
<p>The program in <a class="reference internal" href="example_performance_profiling.cpp.html#doxid-performance-profiling-8cpp-example"><span class="std std-ref">performance_profiling.cpp</span></a> includes all three implementations introduced above. You can select the specific implementation using command line options.</p>
<p>After compilation, you can execute each implementation with:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">program</span><span class="p">.</span><span class="n">exe</span> <span class="p">[</span><span class="n">cpu</span><span class="o">|</span><span class="n">gpu</span><span class="p">]</span> <span class="p">[</span><span class="n">implementation</span><span class="p">]</span></pre>
<p>Before you run the program, set your <code class="docutils literal notranslate"><span class="pre">ONEDNN_VERBOSE</span></code> environment variable to <code class="docutils literal notranslate"><span class="pre">profile_exec</span></code> :</p>
<pre class="highlight literal-block"><span></span><span class="k">export</span> <span class="n">ONEDNN_VERBOSE</span><span class="o">=</span><span class="n">profile_exec</span></pre>
<p>The program starts by creating oneDNN memory objects in NCHW format. These are called <code class="docutils literal notranslate"><span class="pre">user_</span></code> because they are meant to represent the user’s source data entering oneDNN with the NCHW format.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// set dimensions for synthetic data and weights</span>
<span class="k">const</span> <span class="n">memory</span><span class="o">::</span><span class="n">dim</span> <span class="n">BATCH</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
<span class="k">const</span> <span class="n">memory</span><span class="o">::</span><span class="n">dim</span> <span class="n">IC</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">OC</span> <span class="o">=</span> <span class="mi">96</span><span class="p">;</span>
<span class="k">const</span> <span class="n">memory</span><span class="o">::</span><span class="n">dim</span> <span class="n">IH</span> <span class="o">=</span> <span class="mi">227</span><span class="p">,</span> <span class="n">KH</span> <span class="o">=</span> <span class="mi">11</span><span class="p">,</span> <span class="n">OH</span> <span class="o">=</span> <span class="mi">55</span><span class="p">;</span>
<span class="k">const</span> <span class="n">memory</span><span class="o">::</span><span class="n">dim</span> <span class="n">IW</span> <span class="o">=</span> <span class="mi">227</span><span class="p">,</span> <span class="n">KW</span> <span class="o">=</span> <span class="mi">11</span><span class="p">,</span> <span class="n">OW</span> <span class="o">=</span> <span class="mi">55</span><span class="p">;</span></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here the library allocates memory.</p>
</div>
<pre class="highlight literal-block"><span></span><span class="c1">// create oneDNN memory objects for user&#39;s tensors (in nchw and oihw formats)</span>
<span class="k">auto</span> <span class="n">user_src</span> <span class="o">=</span> <span class="n">memory</span><span class="p">({{</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">IC</span><span class="p">,</span> <span class="n">IH</span><span class="p">,</span> <span class="n">IW</span><span class="p">},</span> <span class="n">memory</span><span class="o">::</span><span class="n">data_type</span><span class="o">::</span><span class="n">f32</span><span class="p">,</span>
                               <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">nchw</span><span class="p">},</span>
        <span class="n">eng</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">user_wei</span> <span class="o">=</span> <span class="n">memory</span><span class="p">({{</span><span class="n">OC</span><span class="p">,</span> <span class="n">IC</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">},</span> <span class="n">memory</span><span class="o">::</span><span class="n">data_type</span><span class="o">::</span><span class="n">f32</span><span class="p">,</span>
                               <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">oihw</span><span class="p">},</span>
        <span class="n">eng</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">user_dst</span> <span class="o">=</span> <span class="n">memory</span><span class="p">({{</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">OC</span><span class="p">,</span> <span class="n">OH</span><span class="p">,</span> <span class="n">OW</span><span class="p">},</span> <span class="n">memory</span><span class="o">::</span><span class="n">data_type</span><span class="o">::</span><span class="n">f32</span><span class="p">,</span>
                               <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">nchw</span><span class="p">},</span>
        <span class="n">eng</span><span class="p">);</span></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can change the batch size to easily increase/decrease the workload.</p>
</div>
<p>The following descriptions of each implementation will reference each other, and are meant to be read in order.</p>
</section>
<section id="naive-implementation">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-implementation1"></span><h2>Naive Implementation<a class="headerlink" href="#naive-implementation" title="Permalink to this heading">#</a></h2>
<p>This implementation is launched with the following shell code:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">program</span><span class="p">.</span><span class="n">exe</span> <span class="n">cpu</span> <span class="n">naive</span></pre>
<p>The program will call the implementation defined in the function <code class="docutils literal notranslate"><span class="pre">conv_relu_naive()</span></code>.</p>
<p>First it sets the dimensions and format for convolution memory descriptors (<code class="docutils literal notranslate"><span class="pre">_md</span></code>) to match <code class="docutils literal notranslate"><span class="pre">user_</span></code> values one <code class="docutils literal notranslate"><span class="pre">md</span></code> each for source, destination, and weight data. Then it uses those <code class="docutils literal notranslate"><span class="pre">md</span></code> to create the convolution primitive descriptor <code class="docutils literal notranslate"><span class="pre">conv_pd</span></code>, which tells oneDNN to use plain format (NCHW) for the convolution.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// copy the dimensions and format from user&#39;s memory</span>
<span class="k">auto</span> <span class="n">conv_src_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_src</span><span class="p">.</span><span class="n">get_desc</span><span class="p">());</span>
<span class="k">auto</span> <span class="n">conv_wei_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_wei</span><span class="p">.</span><span class="n">get_desc</span><span class="p">());</span>
<span class="k">auto</span> <span class="n">conv_dst_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_dst</span><span class="p">.</span><span class="n">get_desc</span><span class="p">());</span></pre>
<p>Next the program creates a convolution primitive descriptor <code class="docutils literal notranslate"><span class="pre">conv_pd</span></code> and convolution primitive <code class="docutils literal notranslate"><span class="pre">conv</span></code>. These structs will inherit NCHW format from <code class="docutils literal notranslate"><span class="pre">md</span></code> by way of the <code class="docutils literal notranslate"><span class="pre">conv_d</span></code>. Finally it creates the convolution primitive <code class="docutils literal notranslate"><span class="pre">conv</span></code> and adds it to the stream <code class="docutils literal notranslate"><span class="pre">s</span></code>, and then executes the <code class="docutils literal notranslate"><span class="pre">create_and_execute_relu(user_dst)</span></code> function.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// create a convolution primitive descriptor</span>
<span class="k">auto</span> <span class="n">conv_pd</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="o">::</span><span class="n">primitive_desc</span><span class="p">(</span><span class="n">eng</span><span class="p">,</span>
        <span class="n">prop_kind</span><span class="o">::</span><span class="n">forward_inference</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">::</span><span class="n">convolution_direct</span><span class="p">,</span>
        <span class="n">conv_src_md</span><span class="p">,</span> <span class="n">conv_wei_md</span><span class="p">,</span> <span class="n">conv_dst_md</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// create convolution primitive</span>
<span class="k">auto</span> <span class="n">conv</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">);</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// execute convolution by adding it to the stream s</span>
<span class="n">conv</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">s</span><span class="p">,</span>
        <span class="p">{{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gac37ad67b48edeb9e742af0e50b70fe09"><span class="std std-ref">DNNL_ARG_SRC</span></a><span></span><span class="p">,</span> <span class="n">user_src</span><span class="p">},</span> <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gaf279f28c59a807e71a70c719db56c5b3"><span class="std std-ref">DNNL_ARG_WEIGHTS</span></a><span></span><span class="p">,</span> <span class="n">user_wei</span><span class="p">},</span>
                <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1ga3ca217e4a06d42a0ede3c018383c388f"><span class="std std-ref">DNNL_ARG_DST</span></a><span></span><span class="p">,</span> <span class="n">user_dst</span><span class="p">}});</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// execute relu (on convolution&#39;s destination format, whatever it is)</span>
<span class="n">create_and_execute_relu</span><span class="p">(</span><span class="n">user_dst</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">s</span><span class="p">);</span>
<span class="n">s</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The function for creation and execution of ReLU primitive is defined elsewhere to keep this example clean. It is an non-intensive operation, so the <code class="docutils literal notranslate"><span class="pre">create_and_execute_relu()</span></code> function uses whatever the input data format is at the time it is called.</p>
</div>
<p>Using NCHW data format may result in suboptimal performance for compute intensive primitives, as shown in the following ONEDNN_VERBOSE output by the convolution and relu execution times of 38.3 and 2.9 milliseconds, respectively.</p>
<p>ONEDNN_VERBOSE output (see configuration notice*):</p>
<pre class="highlight literal-block"><span></span><span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">convolution</span><span class="p">,</span><span class="nl">gemm</span><span class="p">:</span><span class="n">jit</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">wei_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">bia_undef</span><span class="o">::</span><span class="n">undef</span><span class="o">::</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span><span class="p">,,</span><span class="nl">alg</span><span class="p">:</span><span class="n">convolution_direct</span><span class="p">,</span><span class="n">mb128_ic3oc96_ih227oh55kh11sh4dh0ph0_iw227ow55kw11sw4dw0pw0</span><span class="p">,</span><span class="mf">38.314</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">eltwise</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">avx512_common</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">data_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">diff_undef</span><span class="o">::</span><span class="n">undef</span><span class="o">::</span><span class="n">f0</span><span class="p">,,</span><span class="nl">alg</span><span class="p">:</span><span class="n">eltwise_relu</span> <span class="nl">alpha</span><span class="p">:</span><span class="mi">0</span> <span class="nl">beta</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="mi">128</span><span class="n">x96x55x55</span><span class="p">,</span><span class="mf">2.87695</span></pre>
<p>In Blocked format implementation, we will incorporate the best practice of letting oneDNN determine the optimal format for convolution primitive.</p>
</section>
<section id="blocked-format-implementation">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-implementation2"></span><h2>Blocked format implementation<a class="headerlink" href="#blocked-format-implementation" title="Permalink to this heading">#</a></h2>
<p>This implementation is launched with the following shell code:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">program</span><span class="p">.</span><span class="n">exe</span> <span class="n">cpu</span> <span class="n">blocked</span></pre>
<p>The program will call the implementation defined in the function <code class="docutils literal notranslate"><span class="pre">conv_relu_blocked()</span></code>.</p>
<p>First it creates the md as in naive implementation. Next it changes the <a class="reference internal" href="enum_dnnl_memory_format_tag.html#doxid-structdnnl-1-1memory-1a8e71077ed6a5f7fb7b3e6e1a5a2ecf3f"><span class="std std-ref">dnnl::memory::format_tag</span></a> for each md to <code class="docutils literal notranslate"><span class="pre">ANY</span></code>. Then it uses those md to create the convolution primitive descriptor conv_pd, which tells oneDNN to use whatever format it recommends for the convolution. oneDNN will choose a friendly blocked format.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// copy the dimensions and data type from user&#39;s memory and set format tag</span>
<span class="c1">// to &quot;any&quot; to allow convolution to pick the best implementation</span>
<span class="k">auto</span> <span class="n">conv_src_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_src</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_dims</span><span class="p">(),</span>
        <span class="n">user_src</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_data_type</span><span class="p">(),</span> <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">any</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">conv_wei_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_wei</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_dims</span><span class="p">(),</span>
        <span class="n">user_wei</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_data_type</span><span class="p">(),</span> <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">any</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">conv_dst_md</span> <span class="o">=</span> <span class="n">memory</span><span class="o">::</span><span class="n">desc</span><span class="p">(</span><span class="n">user_dst</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_dims</span><span class="p">(),</span>
        <span class="n">user_dst</span><span class="p">.</span><span class="n">get_desc</span><span class="p">().</span><span class="n">get_data_type</span><span class="p">(),</span> <span class="n">memory</span><span class="o">::</span><span class="n">format_tag</span><span class="o">::</span><span class="n">any</span><span class="p">);</span></pre>
<p>Next the program creates a convolution primitive descriptor conv_pd and convolution primitive conv as in naive implementation. However, in this implementation the structs will inherit blocked format from md by way of the conv_d.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// create a convolution primitive descriptor and primitive</span>
<span class="k">auto</span> <span class="n">conv_pd</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="o">::</span><span class="n">primitive_desc</span><span class="p">(</span><span class="n">eng</span><span class="p">,</span>
        <span class="n">prop_kind</span><span class="o">::</span><span class="n">forward_inference</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">::</span><span class="n">convolution_direct</span><span class="p">,</span>
        <span class="n">conv_src_md</span><span class="p">,</span> <span class="n">conv_wei_md</span><span class="p">,</span> <span class="n">conv_dst_md</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span></pre>
<p>Since the resulting convolution primitive will expect blocked source data, conditional reorders are inserted to convert input data to blocked format if required. The input data user_src is NCHW, so this conditional will be triggered:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The reoders are applied using oneDNN <code class="docutils literal notranslate"><span class="pre">reorder</span></code> primitive.</p>
</div>
<pre class="highlight literal-block"><span></span><span class="c1">// prepare convolution source</span>
<span class="n">memory</span> <span class="n">conv_src</span> <span class="o">=</span> <span class="n">user_src</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">src_desc</span><span class="p">()</span> <span class="o">!=</span> <span class="n">user_src</span><span class="p">.</span><span class="n">get_desc</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">conv_src</span> <span class="o">=</span> <span class="n">memory</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">src_desc</span><span class="p">(),</span> <span class="n">eng</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">r_pd</span> <span class="o">=</span> <span class="n">reorder</span><span class="o">::</span><span class="n">primitive_desc</span><span class="p">(</span><span class="n">user_src</span><span class="p">,</span> <span class="n">conv_src</span><span class="p">);</span>
    <span class="n">reorder</span><span class="p">(</span><span class="n">r_pd</span><span class="p">).</span><span class="n">execute</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">user_src</span><span class="p">,</span> <span class="n">conv_src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// prepare convolution weights</span>
<span class="n">memory</span> <span class="n">conv_wei</span> <span class="o">=</span> <span class="n">user_wei</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">weights_desc</span><span class="p">()</span> <span class="o">!=</span> <span class="n">user_wei</span><span class="p">.</span><span class="n">get_desc</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">conv_wei</span> <span class="o">=</span> <span class="n">memory</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">weights_desc</span><span class="p">(),</span> <span class="n">eng</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">r_pd</span> <span class="o">=</span> <span class="n">reorder</span><span class="o">::</span><span class="n">primitive_desc</span><span class="p">(</span><span class="n">user_wei</span><span class="p">,</span> <span class="n">conv_wei</span><span class="p">);</span>
    <span class="n">reorder</span><span class="p">(</span><span class="n">r_pd</span><span class="p">).</span><span class="n">execute</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">user_wei</span><span class="p">,</span> <span class="n">conv_wei</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// prepare convolution destination</span>
<span class="n">memory</span> <span class="n">conv_dst</span> <span class="o">=</span> <span class="n">user_dst</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">dst_desc</span><span class="p">()</span> <span class="o">!=</span> <span class="n">user_dst</span><span class="p">.</span><span class="n">get_desc</span><span class="p">())</span>
    <span class="n">conv_dst</span> <span class="o">=</span> <span class="n">memory</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">.</span><span class="n">dst_desc</span><span class="p">(),</span> <span class="n">eng</span><span class="p">);</span></pre>
<p>Finally it creates the convolution primitive <code class="docutils literal notranslate"><span class="pre">conv</span></code> and adds it to the stream <code class="docutils literal notranslate"><span class="pre">s</span></code> with the reordered data (<code class="docutils literal notranslate"><span class="pre">conv_src</span></code>, <code class="docutils literal notranslate"><span class="pre">conv_wei</span></code>, <code class="docutils literal notranslate"><span class="pre">conv_dst1</span></code>) as inputs and then executes the <code class="docutils literal notranslate"><span class="pre">create_and_execute_relu(conv_dst)</span></code> function.</p>
<pre class="highlight literal-block"><span></span><span class="c1">// create convolution primitive</span>
<span class="k">auto</span> <span class="n">conv</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">);</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// execute convolution by adding it to the stream s</span>
<span class="n">conv</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">s</span><span class="p">,</span>
        <span class="p">{{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gac37ad67b48edeb9e742af0e50b70fe09"><span class="std std-ref">DNNL_ARG_SRC</span></a><span></span><span class="p">,</span> <span class="n">conv_src</span><span class="p">},</span> <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gaf279f28c59a807e71a70c719db56c5b3"><span class="std std-ref">DNNL_ARG_WEIGHTS</span></a><span></span><span class="p">,</span> <span class="n">conv_wei</span><span class="p">},</span>
                <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1ga3ca217e4a06d42a0ede3c018383c388f"><span class="std std-ref">DNNL_ARG_DST</span></a><span></span><span class="p">,</span> <span class="n">conv_dst</span><span class="p">}});</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// execute relu (on convolution&#39;s destination format, whatever it is)</span>
<span class="n">create_and_execute_relu</span><span class="p">(</span><span class="n">conv_dst</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">s</span><span class="p">);</span></pre>
<p>Blocked memory format is recommended for oneDNN primitive execution and provides better performance, as shown in the ONEDNN_VERBOSE output by the convolution and relu execution times of 18.3 and 2.7 milliseconds (down from 38.3 and 2.9 in naive implementation), respectively. In this implementation, there is an additional reorder operation that executes before and after the the conv + relu. This small cost is worth the gain from executing in blocked format. If fact, it becomes negligible when chaining together multiple oneDNN operations in succession. In these situations, you can do one reorder at the beginning and one at the end of the chain, and only pay the reorder penalty at those points in the execution.</p>
<p>ONEDNN_VERBOSE output (see configuration notice*):</p>
<pre class="highlight literal-block"><span></span><span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">Acdb16a</span><span class="p">:</span><span class="n">f0</span><span class="p">,,,</span><span class="mi">96</span><span class="n">x3x11x11</span><span class="p">,</span><span class="mf">0.0310059</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">convolution</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">avx512_common</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">wei_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">Acdb16a</span><span class="p">:</span><span class="n">f0</span> <span class="n">bia_undef</span><span class="o">::</span><span class="n">undef</span><span class="o">::</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">aBcd16b</span><span class="p">:</span><span class="n">f0</span><span class="p">,,</span><span class="nl">alg</span><span class="p">:</span><span class="n">convolution_direct</span><span class="p">,</span><span class="n">mb128_ic3oc96_ih227oh55kh11sh4dh0ph0_iw227ow55kw11sw4dw0pw0</span><span class="p">,</span><span class="mf">18.3101</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">eltwise</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">avx512_common</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">data_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">aBcd16b</span><span class="p">:</span><span class="n">f0</span> <span class="n">diff_undef</span><span class="o">::</span><span class="n">undef</span><span class="o">::</span><span class="n">f0</span><span class="p">,,</span><span class="nl">alg</span><span class="p">:</span><span class="n">eltwise_relu</span> <span class="nl">alpha</span><span class="p">:</span><span class="mi">0</span> <span class="nl">beta</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="mi">128</span><span class="n">x96x55x55</span><span class="p">,</span><span class="mf">2.66895</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">aBcd16b</span><span class="p">:</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span><span class="p">,,,</span><span class="mi">128</span><span class="n">x96x55x55</span><span class="p">,</span><span class="mf">4.80396</span></pre>
<p>This inference implementation is closer to best practices than naive implementation because it uses oneDNN recommended memory format. fused implementation will further optimize the performance by fusing convolution with ReLU using oneDNN <a class="reference internal" href="dev_guide_attributes_post_ops.html#doxid-dev-guide-attributes-post-ops"><span class="std std-ref">post-ops</span></a>.</p>
</section>
<section id="fused-implementation">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-implementation3"></span><h2>Fused Implementation<a class="headerlink" href="#fused-implementation" title="Permalink to this heading">#</a></h2>
<p>This implementation is launched with the following shell code:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">program</span><span class="p">.</span><span class="n">exe</span> <span class="n">cpu</span> <span class="n">fused</span></pre>
<p>The program will call the implementation defined in the function <code class="docutils literal notranslate"><span class="pre">conv_relu_fused()</span></code>.</p>
<p>First the memory descriptors and convolution primitive descriptor are created as in naive implementation.</p>
<p>Then in preparation for the convolution prim descriptor, a ReLU post-op is built and added to the primitive attribute <code class="docutils literal notranslate"><span class="pre">attr</span></code> :</p>
<pre class="highlight literal-block"><span></span><span class="c1">// function to create post-op attribute for fused relu</span>
<span class="n">primitive_attr</span> <span class="nf">create_attr_with_relu_post_op</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// create a post-op with relu</span>
    <span class="n">post_ops</span> <span class="n">ops</span><span class="p">;</span>
    <span class="n">ops</span><span class="p">.</span><span class="n">append_eltwise</span><span class="p">(</span><span class="n">algorithm</span><span class="o">::</span><span class="n">eltwise_relu</span><span class="p">,</span> <span class="mf">0.f</span><span class="p">,</span> <span class="mf">0.f</span><span class="p">);</span>

    <span class="c1">// create an attribute and set the corresponding post op</span>
    <span class="n">primitive_attr</span> <span class="n">attr</span><span class="p">;</span>
    <span class="n">attr</span><span class="p">.</span><span class="n">set_post_ops</span><span class="p">(</span><span class="n">ops</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">attr</span><span class="p">;</span>
<span class="p">}</span></pre>
<p>post-op by way of the attributes <code class="docutils literal notranslate"><span class="pre">attr</span></code> :</p>
<pre class="highlight literal-block"><span></span><span class="c1">// create an attribute for fused relu</span>
<span class="k">auto</span> <span class="n">attr</span> <span class="o">=</span> <span class="n">create_attr_with_relu_post_op</span><span class="p">();</span>

<span class="c1">// create a convolution primitive descriptor</span>
<span class="k">auto</span> <span class="n">conv_pd</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="o">::</span><span class="n">primitive_desc</span><span class="p">(</span><span class="n">eng</span><span class="p">,</span>
        <span class="n">prop_kind</span><span class="o">::</span><span class="n">forward_inference</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">::</span><span class="n">convolution_direct</span><span class="p">,</span>
        <span class="n">conv_src_md</span><span class="p">,</span> <span class="n">conv_wei_md</span><span class="p">,</span> <span class="n">conv_dst_md</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
        <span class="n">attr</span><span class="p">);</span></pre>
<p>Then conditional reorders are applied as in blocked format implementation to convert <code class="docutils literal notranslate"><span class="pre">user_</span></code> format NCHW to blocked. Finally, it creates the convolution primitive <code class="docutils literal notranslate"><span class="pre">conv</span></code> and adds it to the stream <code class="docutils literal notranslate"><span class="pre">s</span></code> with the reordered data (<code class="docutils literal notranslate"><span class="pre">conv_src</span></code>, <code class="docutils literal notranslate"><span class="pre">conv_wei</span></code>, <code class="docutils literal notranslate"><span class="pre">conv_dst1</span></code>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is no separate addition to the stream for the ReLU operation because it has been added as a post-op to the <code class="docutils literal notranslate"><span class="pre">conv</span></code> primitive.</p>
</div>
<pre class="highlight literal-block"><span></span><span class="c1">// create convolution primitive</span>
<span class="k">auto</span> <span class="n">conv</span> <span class="o">=</span> <span class="n">convolution_forward</span><span class="p">(</span><span class="n">conv_pd</span><span class="p">);</span></pre>
<pre class="highlight literal-block"><span></span><span class="c1">// execute convolution by adding it to the stream s</span>
<span class="n">conv</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">s</span><span class="p">,</span>
        <span class="p">{{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gac37ad67b48edeb9e742af0e50b70fe09"><span class="std std-ref">DNNL_ARG_SRC</span></a><span></span><span class="p">,</span> <span class="n">conv_src</span><span class="p">},</span> <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1gaf279f28c59a807e71a70c719db56c5b3"><span class="std std-ref">DNNL_ARG_WEIGHTS</span></a><span></span><span class="p">,</span> <span class="n">conv_wei</span><span class="p">},</span>
                <span class="p">{</span><a class="reference internal" href="group_dnnl_api_primitives_common.html#doxid-group-dnnl-api-primitives-common-1ga3ca217e4a06d42a0ede3c018383c388f"><span class="std std-ref">DNNL_ARG_DST</span></a><span></span><span class="p">,</span> <span class="n">conv_dst</span><span class="p">}});</span></pre>
<p>This implementation complies with best practices for f32 inference by using the oneDNN recommended blocked format for convolution and adding ReLU as a post-op to execute a fused version of conv + ReLU. The consequence to following best practices can be seen in the execution time of the fused primitive of 18.0 milliseconds.</p>
<p>ONEDNN_VERBOSE output (see configuration notice*):</p>
<pre class="highlight literal-block"><span></span><span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">Acdb16a</span><span class="p">:</span><span class="n">f0</span><span class="p">,,,</span><span class="mi">96</span><span class="n">x3x11x11</span><span class="p">,</span><span class="mf">0.0148926</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">convolution</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">avx512_common</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span> <span class="n">wei_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">Acdb16a</span><span class="p">:</span><span class="n">f0</span> <span class="n">bia_undef</span><span class="o">::</span><span class="n">undef</span><span class="o">::</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">aBcd16b</span><span class="p">:</span><span class="n">f0</span><span class="p">,</span><span class="nl">post_ops</span><span class="p">:</span><span class="sc">&#39;eltwise_relu;&#39;</span><span class="p">;,</span><span class="nl">alg</span><span class="p">:</span><span class="n">convolution_direct</span><span class="p">,</span><span class="n">mb128_ic3oc96_ih227oh55kh11sh4dh0ph0_iw227ow55kw11sw4dw0pw0</span><span class="p">,</span><span class="mf">17.968</span>
<span class="n">onednn_verbose</span><span class="p">,</span><span class="n">v0</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">cpu</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="nl">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="n">src_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">aBcd16b</span><span class="p">:</span><span class="n">f0</span> <span class="n">dst_f32</span><span class="o">::</span><span class="nl">blocked</span><span class="p">:</span><span class="nl">abcd</span><span class="p">:</span><span class="n">f0</span><span class="p">,,,</span><span class="mi">128</span><span class="n">x96x55x55</span><span class="p">,</span><span class="mf">4.66797</span></pre>
</section>
<section id="performance-summary">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-roundup"></span><h2>Performance summary<a class="headerlink" href="#performance-summary" title="Permalink to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Implementation</p></th>
<th class="head"><p>Time, ms</p></th>
<th class="head"><p>Cumulative speedup</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Naive</p></td>
<td><p>41.2</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Blocked format</p></td>
<td><p>21.0</p></td>
<td><p>2.0</p></td>
</tr>
<tr class="row-even"><td><p>Fused</p></td>
<td><p>18.0</p></td>
<td><p>2.3</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="configuration-notice">
<span id="doxid-performance-profiling-cpp-1performance-profiling-cpp-config"></span><h2>Configuration Notice<a class="headerlink" href="#configuration-notice" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This example is meant to demonstrate oneDNN best practices.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is not meant for benchmarking purposes. The platform is not fully</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>optimized, so the primitive execution times are only relevant in</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>relation to the other times in this example.</p>
</div>
<p>Runtime Settings:</p>
<ul class="simple">
<li><p>OMP_NUM_THREADS=14</p></li>
<li><p>KMP_AFFINITY=granularity=fine,compact</p></li>
</ul>
<p>Platform:</p>
<ul class="simple">
<li><p>CPU: Intel(R) Xeon(R) Platinum 8180 CPU &#64; 2.50GHz</p></li>
<li><p>Thread(s) per core: 1</p></li>
<li><p>Core(s) per socket: 28</p></li>
<li><p>Socket(s): 2</p></li>
<li><p>NUMA node(s): 2</p></li>
<li><p>RAM (DDR4): 192 GB</p></li>
</ul>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="dev_guide_inspecting_jit.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Inspecting JIT Code</p>
      </div>
    </a>
    <a class="right-next"
       href="dev_guide_cpu_dispatcher_control.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CPU Dispatcher Control</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#walkthrough">Walkthrough</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-implementation">Naive Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#blocked-format-implementation">Blocked format implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fused-implementation">Fused Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-summary">Performance summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-notice">Configuration Notice</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2016-2025 Intel Corporation.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>